<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {
            background-image: linear-gradient(to bottom, #EBFAFB, #A0F5FB);
            background-attachment: fixed;
        }
        h1 {
            background-color: rgba(5, 5, 151, 0.568);
            text-shadow: 1px 1px 0px rgba(3, 3, 114, 0.568);
            color: white;
            text-align: center;
        }
        h2 {
            background-color: rgba(0, 128, 0, 0.514);
            color: white;
            text-align: center;
        }
        p {
            text-align: justify;
            color: black;
        }
        mark {
            background-color: yellow;
            color: black;   
            font-weight: bold;           
        }
        code {
            font-family: 'Times New Roman', Times, serif;
            font-weight: bold;
        }
        table, th, td {
            border: 1px solid black;
            text-align: center;
        }
    </style>
    <title>Teste</title>

</head>
<body>
    <h1>Revisão</h1>
    <h2>Semana 1</h2>
    <p>
        No início da nossa disciplina, você irá conhecer conceitos de organização e arquitetura de computadores. <br>

        Começamos com algumas definições e uma breve história do computador, apresentando a evolução das máquinas computacionais de acordo com as mudanças das arquiteturas e organizações dos computadores, impulsionadas, com o passar do tempo, por momentos históricos, como a Segunda Guerra Mundial. <br>

        Para fechar a semana, vamos conhecer dois importantes modelos de computador: o modelo do grande matemático inglês Turing e o modelo de von Neumann. <br> <br>

        Habilidades e competências:

        <ul>
            <li>Entender os conceitos de Arquitetura e Organização de Computadores;</li>
            <li>Conhecer aspectos da história das máquinas computacionais e os modelos criados para elas.</li>
        </ul>
    </p>
    <h4>O computador</h4>
    <ul>
        <li>composto de hardware e software</li>
        <li>estrutura hierárquica &rarr; sistemas e subsistemas com interrelacionamentos</li>
        <li>memória &rarr; dividida em principal (RAM) e auxiliar (SS/HD/Flash)</li>
        <li>CPU &rarr; Unidade Central de Processamento</li>
            <ul type="square">
                <li>controla a operação do computador</li>
                <li>processa os dados de entrada</li>
                <li>dividida em UC, ULA e registradores</li>
                    <ul type="circle">
                        <li>UC &rarr; controla toda a operação da CPU</li>
                        <li>ULA &rarr; processa dados</li>
                        <li>Registradores &rarr; armazena em cache interno para a CPU. Mais rápido que buscar dados na memória principal e secundária</li>
                    </ul>                    
            </ul>
        <li>Unidade de entrada &rarr; teclados, leitores de código de barras etc</li>
        <li>Unidade de saída &rarr; monitor, porta de impressão etc</li>
        <li>Interconexões do sistema &rarr; faz a comunicação entre UC, ULA, memórias, E/S,  ULA e registradores (é o barramento)</li>
    </ul>
    <h4>Funções básicas do computador</h4>
    <ul>
        <li>Processamento de dados &rarr; manipular os dados</li>
        <li>Armazenamento de dados &rarr; para processar rapidamente (RAM) e a longo prazo (SS/HD/Flash)</li>
        <li>E/S &rarr; entrada e saída de dados com o mundo externo</li>
        <li>Controle &rarr; coordena todas as funções. Gerencia recursos</li>
    </ul>
    <h4>Classificação dos computadores</h4>
    <ul>
        <li>Operação &rarr; analógico e digital</li>
        <li>Utilização &rarr; científico e comercial</li>
        <li>Construção &rarr; 1ª geração Válvulas</li>
            <ul type="square">
                <li>mecânicos &rarr; 1ª Geração</li>
                    <ul type="circle">
                        <li>Pascal &rarr; (1623-1662)</li>
                        <li>Leibniz &rarr; (1646-1716) ad/sub/mult/div</li>
                        <li>Babbage &rarr; (1792-1871) com memória, E/S (cartão perfurado) e cálculos</li>
                        <li>Turing &rarr; (1912-1954) criou o Colossus. 1ª geração à válvula</li>
                        <li>ENIAC &rarr; (1943-1946) com 18k válvulas e 30 toneladas</li>
                        <li>IBM &rarr; (1954) criou o 701 e dominou por uma década</li>                        
                    </ul>
                <li>transistorizados &rarr; 2ª geração (milissegundos)</li>
                    <ul>
                        <li>1948 &rarr; criação do transistor. TX-0 foi o primeiro computador</li>
                        <li>1960</li>
                            <ul type="circle">
                                <li>DEC lançou a PDP-1, similar ao TX-0</li>
                                <li>Nasce a indústria de minicomputadores</li>
                                <li>DEC lança a PDP-8 com barramento único</li>
                                <li>IBM lança computadores transistorizados (7090 e 7094)</li>
                            </ul>
                        <li>1964</li>
                            <ul type="circle">
                                <li>CDC lança o 6600 mais barato, mais rápido e com paralelismo de processamento</li>
                                <li>Algol60 &rarr; primórdio da criação da linguagem C e Java. Início da importância do software</li>
                            </ul>
                    </ul>
                <li>Circuitos Integrados &rarr; 3ª geração (nanossegundos)</li>
                    <ul type="disc">
                        <li>1958 &rarr; CI de silício, dezenas de transistores por chip, computador menor, mais rápido e barato</li>
                        <li>1964 &rarr; IBM lança a System/360 (baseado em CI), multiprograma na memória e melhor processamento. DEC lança o PDP-11 e evolui nos minicomputadores (usado em universidades)</li>                      
                    </ul>
                <li>4ª Geração &rarr; Atual (milhões de transistores por chip)</li>
                    <ul type="disc">
                        <li>1980</li>
                            <ul type="circle">
                                <li>criação da tecnologia VLSI (Integração em altíssima escala)</li>
                                <li>computadores ainda menores e mais rápidos</li>
                                <li>preços menores (se começa a pensar em um computador por pessoa)</li>
                                <li>era do computador pessoal</li>
                                <li>Apple e IBM lançam computadores pessoais</li>
                                <li>Microsoft cria o Windows</li>
                                <li>A arquitetura RISC começa a substituir a CISC</li>
                            </ul>
                    </ul>
            </ul>        
    </ul>
    <h4>Modelos de computadores</h4>
    <ul>
        <li>Modelo de Turing</li>
            <ul>
                <li>desevolvido pelo matemático Alan Turing em 1937</li>
                <li>primeira descrição de um computador moderno</li>
                <li>recebe os dados de entrada e o programa (ficam armazenados) para dar função ao hardware</li>
                <li>deu origem ao computador com programa armazenado</li>
            </ul>
        <li>Modelo de Von Neumann</li>
            <ul>
                <li>base de quase todos os computadores modernos</li>
                <li>posterior ao modelo de Turing</li>
                <li>é funcional mas limita a velocidade de processamento (por ser processamento serial)</li>
                <li>composto por 4 partes básicas</li>
                <li>memória &rarr; armazena dados e programas</li>
                <li>ULA &rarr; realiza operações lógicas e matemáticas. Tem internamente um Acumulador com 40 bits de tamanho de palavras</li>
                <li>E/S &rarr; recebe dados e emite saídas após processamento</li>
                <li>UC &rarr; faz o controle da memória, ULA, UC e E/S</li>
            </ul>
        <li>Outros modelo (modelos não Von Neumann)</li>
            <ul>
                <li>Paralel &rarr; distribuição em unidades de processamento que atuam em paralelo (redes neurais, algoritmos genéticos, computação quântica, de fluxo de dados e computadores paralelos)</li>
            </ul>
    </ul>    
    <hr>
    <h2>Semana 2</h2>   
    <p>
        Nesta semana, você conhecerá mais profundamente as funções, transações e interações da CPU, barramentos, memórias do computador, dispositivos externos de armazenamento e de periféricos de E/S. A CPU será apresentada, em maiores detalhes, em termos de seus componentes, ciclo de execução e barramentos. O estudo da CPU é finalizado com uma apresentação resumida das arquiteturas Cisc e Risc com suas motivações e principais características. Na segunda aula da semana, destaco as memórias com seus tipos, características e funcionamento. O estudo sobre memórias é continuado na terceira aula considerando os sistemas externos de armazenamento de dados. Para fechar a semana, apresentamos os periféricos que eram dispositivos simples e básicos da época dos terminais e dos grandes computadores rudimentares; mas, atualmente, estão conectados a computadores pessoais com grande poder tecnológico de touch screen, câmeras de altíssima definição, impressoras 3D, entre outros. <br> <br>

        Habilidades e competências:

        <ul>
            <li>Entenda as principais características, funções e interações da CPU, dos barramentos, das memórias em seus diferentes tipos e dos periféricos de E/S.</li>
        </ul>
    </p>
    <h4>Unidade Central de Processamento (<mark>CPU</mark>)</h4>
        <ul>
            <li>cérebro do computador</li>
            <li>executa programas em sequência, armazenados na RAM. Chamado de ciclo da máquina</li>
            <li>controla componentes e subsistemas</li>
            <li>composta por UC, ULA e Registradores (cache interno). Tem também um barramento principal</li>            
        </ul>
    <h4>Unidade de Controle (<mark>UC</mark>)</h4>
        <ul>
            <li>controla o funcionamento de cada subsistema interligado ao barramento</li>
            <li>busca instruções na memória principal</li>
            <li>determina o tipo dessa instrução</li>
        </ul>
    <h4>Unidade Lógica e Aritmética (<mark>ULA</mark>)</h4>
        <ul>
            <li>recebe dados da UC e de registradores</li>
            <li>faz operações matemáticas e lógicas das instruções recebidas</li>
            <li>faz operações de deslocamento lógico (desloca binários para esquerda ou direita)</li>
            <li>faz operações de deslocamento aritmético (dividir ou multiplicar números inteiros por 2)</li>
            <li>escreve bits de saída</li>
            <li>escreve dados em outros registradores</li>
        </ul>
    <h4>Registradores</h4>
        <ul>
            <li>memórias de grande velocidade</li>
            <li>serve de armazenamento temporário e muito rápido</li>
            <li>ficam dentro do processador</li>
            <li>existem diferentes tipos de registradores</li>
                <ul>
                    <li>contador de programa &rarr; é considerado o registrador mais importante (indica a próxima instrução a ser executada. ponteiro)</li>
                    <li>de instrução &rarr; armazena a instrução que está sendo executada</li>
                    <li>de dados &rarr; manter os dados da entrada e os resultados finais</li>
                </ul>
        </ul>
    <h4>Barramento</h4>
        <ul>
            <li>por onde trafegam dados de entrada e saída com a memória</li>                
            <li>existem vários barramentos em um sistema</li>
            <li>há 3 tipos de barramento entre CPU e memória</li>
                <ul>
                    <li>de dados</li>
                        <ul>
                            <li>diversas linhas de conexão</li>
                            <li>1 bit por vez</li>
                            <li>o # de linhas de conexão depende do tamanho da palavra (16/32/64 bits)</li>
                        </ul>
                    <li>de endereço</li>
                        <ul>
                            <li>acessa a palavra na memória principal</li>
                            <li>o # de linhas depende do endereçamento máximo da memória</li>                            
                        </ul>
                    <li>de controle</li>
                        <ul>
                            <li>faz a comunicação CPU/Memória</li>
                            <li>o # de linhas depende da quantidade de comandos de controle</li>
                        </ul>
                </ul>
        </ul>
    <h4>Ciclo de máquina</h4>
        <ul>
            <li>Início &rarr; há instruções?</li>
                <ul>
                    <li>sim &rarr; Busca &rarr; Decodificação &rarr; Execução</li>
                    <li>não &rarr; Fim</li>
                </ul>
            <li>Busca &rarr; quando o sistema copia a próxima instrução no registrador contador de programas</li>
            <li>Decodificação &rarr; ocorre quando a UC decodifica a instrução e quando ela está no RU (resulta em código binário)</li>
            <li>Execução &rarr; ocorre a execução da tarefa por um componente da CPU (pela ULA p.ex.)</li>
        </ul>
    <h4>Entrada e Saída (<mark>E/S</mark>)</h4>
        <ul>
            <li>comunicam dados ou informações do computador e estão conectados a ele (recebem dados e mostram dados)</li>
            <li>cada dispositivo possui 2 partes</li>
                <ul>
                    <li>controlador &rarr; o meio por onde é feita a conexão do dispositivo. Está contido em uma placa</li>
                    <li>controlador de disco &rarr; controla o dispositivo de armazenamento</li>
                </ul>
            <li>arquitetura E/S com os seguintes componentes</li>
                <ul>
                    <li>blocos de memória</li>
                    <li>módulos de controle no sistema principal e periféricos</li>
                    <li>barramento de E/S (comunicar interna e externamente)</li>
                    <li>interface com dispositivos externos</li>
                    <li>ligação entre o sistema principal e os periféricos</li>
                </ul>    
        </ul>
        <h4>Transmissão de dados</h4>
        <ul>
            <li>pode ser:</li>
                <ul>
                    <li>paralela &rarr; um <strong>byte</strong> por vez (distância &le; 1 metro)</li>
                    <li>serial &rarr; um <strong>bit</strong> por vez e transmitidos por um único condutor</li>
                </ul>
        </ul>
        <h4>Outras arquiteturas</h4>
            <ul>
                <li>Complex Instruction Set Computer (<mark>CISC</mark>)</li>
                    <ul>
                        <li>muitas instruções simples e/ou complexas com tamanhos variáveis</li>
                        <li>instruções do tipo registrador-memória</li>
                        <li>programação mais simples</li>
                        <li>circuitos mais complexos (UC)</li>
                        <li>programação em dois níveis &rarr; porque a CPU não executa instruções complexas (chamado microprogramação)</li>
                            <ul>
                                <li>1º &rarr; transforma uma instrução complexa em simples</li>
                                <li>2º &rarr; executa essa instrução simples na CPU</li>
                                <li>necessita de micro memórias</li>
                            </ul>
                        <li>compilador mais simples</li>
                        <li>acesso a memória por qualquer instrução</li>
                        <li>hardware mais complexo e com frequência mais baixa</li>
                        <li>ex.: Intel x86</li>
                    </ul>
                <li>Reduced Instruction Set Computers (<mark>RISC</mark>)</li>
                    <ul>
                        <li>trabalha com instruções reduzidas e tamanho fixo</li>
                        <li>executadas diretamente pelo circuito processador</li>
                        <li>instruções do tipo registrador-registrador</li>
                        <li>tem cerca de 50 instruções</li>
                        <li>fazem o mínimo possível de operações simples</li>
                        <li>simulam operações complexas</li>
                        <li>a programação é mais difícil e demorada</li>
                        <li>projetada para utilização de pipeline</li>
                        <li>hardware mais simples com frequência mais alta</li>
                    </ul>
            </ul>
        <h4>Memórias</h4>
            <ul>
                <li>Armazena programas e dados</li>
                <li>Tem capacidade de armazenamento</li>
                    <ul>
                        <li>maior capacidade = menor custo por bit</li>
                        <li>maior capacidade = tempo de acesso mais lento</li>
                    </ul>
                <li>Tem tempo e custo de acesso</li>
                    <ul>
                        <li>acesso mais rápido = maior custo por bit</li>
                    </ul>
                <li>Tem durabilidade</li>
                <li>Tem consumo de energia</li>
                <li>Hierarquia de memória</li>
                    <ul>
                        <li>na placa (<mark>onboard</mark>)&rarr; RAM, cache, registradores</li>
                        <li>fora da placa (<mark>offboard</mark>) &rarr; CD, DVD, disco magnéticos</li>
                        <li>offline &rarr; fita magnética</li>
                    </ul>
                <li>Endereçamento</li>
                    <ul>
                        <li>composto por células que armazenam palavras</li>
                        <li>cada célula tem um endereço hexadecimal (inteiros &gt; 0) que vai de 0 a <code>2<sup>n</sup> - 1</code> bits de endereço</li>
                        <li>espaço de endereçamento é o total de endereços de memória</li>
                    </ul>
                <li>Tipos de memória</li>
                    <ul>
                        <li>Memória de acesso aleatório (<mark>RAM</mark>)</li>
                            <ul>
                                <li>pode ser lida e escrita durante o processamento</li>
                                <li>pode ser de dois tipos</li>
                                    <ul>
                                        <li>estática (<mark>SRAM</mark>) &rarr; muito rápida e volátil. Apaga-se no desligamento do sistema. Ex.: cache</li>
                                        <li>dinâmica (<mark>DRAM</mark>) &rarr; muito lenta. Cada célula tem um transistor e um capacitor (1 se carregado ou 0 para não)</li>
                                    </ul>
                            <li>Memória somente de leitura (<mark>ROM</mark>)</li>
                                    <ul>
                                        <li>não pode ser apagada</li>
                                        <li>dados inseridos durante a fabricação</li>
                                        <li>podem ser de 3 tipos</li>
                                            <ul>
                                                <li><mark>PROM</mark> &rarr; ROM programável. pode ser programada <mark>UMA</mark> vez em campo</li>
                                                <li><mark>EPROM</mark> -> ROM programável e apagável. pode ser programada e apagada em campo</li>
                                                <li><mark>EEPROM</mark> -> ROM eletricamente programável e apagável. igual a EPROM e também pode ser removida do computador</li>
                                            </ul>
                                    </ul>
                            <li>Cache</li>
                                    <ul>
                                        <li>pequena capacidade e mais rápida que a RAM</li>
                                        <li>mais lenta que os registradores</li>
                                        <li>guarda as palavras mais acessadas com frequência</li>
                                        <li>possui 2 objetivos</li>
                                            <ul>
                                                <li>se aproximar da velocidade dos registradores</li>
                                                <li>aumentar a capacidade de armazenamento dos registradores a um menor custo</li>
                                            </ul>
                                        <li>transfere dados em palavra com os registradores</li>
                                        <li>transfere dados em bloco com a RAM</li>
                                        <li>possui níveis de velocidade &rarr; L1 &gt; L2 &gt; L3</li>
                                        <li>a busca do processador se inicia nesta ordem: L1 &rarr;L2 &rarr; L3 &rarr; RAM</li>
                                    </ul>
                            </ul>
                    </ul>
            </ul>
        <h4>Sistemas de armazenamento</h4>
            <ul>
                <li>Disco magnético &rarr; prato de alumínio com revestimento magnetizável</li>
                <li>trilha &rarr; sequência de bits lidos ou escritos</li>
                <li>setores &rarr; tem tamanho fixo (512 bytes)</li>
                <li>podem ser</li>
                    <ul>
                        <li>rígidos &rarr; atingem até 15k rpm</li>
                        <li>flexíveis &rarr; atingem até 360 rpm</li>
                    </ul>
                <li>Disco óptico &rarr; criados para armazenar programas de TV</li>
                    <ul>
                        <li>grande capacidade</li>
                        <li>baixo custo</li>
                        <li>tipos principais</li>
                            <ul>
                                <li>Compact Disc (<mark>CD</mark>)</li>
                                    <ul>
                                        <li>memória ROM</li>
                                        <li>gravados somente uma vez por laser</li>
                                    </ul>
                                <li>Digital Video Disc (<mark>DVD</mark>)</li>
                                    <ul>
                                        <li>tem planos iluminados por diodo de laser</li>
                                        <li>lidos por fotodetector</li>
                                        <li>tem depressoes menores</li>
                                        <li>espiral mais estreita</li>
                                        <li>laser vermelho que aumenta sua capacidade em 7 vezes</li>
                                    </ul>
                                <li>arranjo redundante de discos independentes (<mark>RAID</mark>)</li>
                                    <ul>
                                        <li>possui níveis de RAID</li>
                                            <ul>
                                                <li>0 &rarr; disco virtual simulado pelo RAID</li>
                                                <li>1 &rarr; RAID verdadeiro que duplica todos os discos (4 primários e 4 backups)</li>
                                                <li>2 &rarr; atua por palavra ou até por byte</li>
                                                <li>3 &rarr; versão simplificada do RAID 2 (só escreve um bit de paridade no disco)</li>
                                                <li>4 &rarr; trabalha com tiras e não requer drives sincronizados. Se assemelha ao RAID 0</li>
                                                <li>5 &rarr; aperfeiçoamento do RAID 4. Faz balanceamento de carga e grava discos em paralelo</li>
                                            </ul>                                    
                                    </ul>
                            </ul>
                    </ul>
                <li>Futuro do armazenamento</li>
                    <ul>
                        <li>aumento da densidade de dados por:</li>
                            <ul>
                                <li>materiais biológicos &rarr; armazena dados de diferentes maneiras</li>
                                <li>microeletromecânicos (<mark>MEMS</mark>) &rarr; ultrapassa o limite do armazenamento magnético</li>
                                <li>holograma &rarr; imagem tridimensional gerada por manipulação de feixes de laser</li>
                            </ul>
                    </ul>
            </ul>
        <h4>Periféricos de E/S</h4>
            <ul>
                <li>Terminais</li>
                    <ul>
                        <li>não possuem memória secundária</li>
                        <li>só possuiam teclado e monitor</li>
                        <li>ligados ao processador central por linha serial ou telefônica</li>
                        <li>caíram em desuso devido ao barateamento dos computadores pessoais</li>
                    </ul>
                <li>Teclado &rarr; mecânicos</li>
                <li>Mouse &rarr; dispositivo apontador</li>
                    <ul>
                        <li>mecânico &rarr; com esfera rotacional</li>
                        <li>ótico &rarr; usa led e fotodetector</li>
                        <li>ótico-mecânico &rarr; mistura dos dois anteriores</li>
                        <li>usam conexão USB</li>
                    </ul>
                <li>Telas touch screens</li>
                    <ul>
                        <li>sensíveis ao toque</li>
                        <li>podem ser transparentes como tela de um tablet</li>
                        <li>podem ser opacas como a tela de um notebook</li>
                        <li>dividem-se em</li>
                            <ul>
                                <li>infravermelho &rarr; emissores na borda direita ou superior detectam a posição do toque</li>
                                <li>resistivo &rarr; duas camadas de fios na tela detectam o toque</li>
                                <li>capacitivo &rarr; permitem vários toques simultâneos</li>
                            </ul>           
                    </ul>
            </ul>
        <h4>Câmeras digitais &rarr; funciona com luz onde o filme é substituido por um sensor CCD que se polariza por exposição à luz</h4>
        <h4>Placas de rede e cabos &rarr; promovem a comunicação cabeada e com alta largura de banda</h4>
    <hr>
    <h2>Semana 3</h2>
    <p>
        Nesta semana, você estudará técnicas e atribuições dos sistemas operacionais modernos, as quais incorrem na manipulação e na otimização do gerenciamento e do uso dos recursos disponibilizados pelos modelos das arquiteturas de computadores atuais. Os principais componentes ou recursos tratados são o processador e as memórias que estão envolvidos em processos, escalonamento de processos, gerenciamento de memória, memória virtual, paginação, segmentação, fragmentação e TLB (Translation Lookaside Buffer). <br> <br>

        Habilidades e competências:

        <ul>
            <li>Reconhecer o gerenciamento de recursos realizado pelo sistema operacional incluindo processos, tipos e estados de processos e escalonamento de processos operados pelo processador e pela memória.</li>
            <li>Entender o particionamento e o gerenciamento de memória, incluindo a memória virtual com o manuseio da hierarquia de memórias entre memória principal e disco.</li>
            <li>Aprender endereçamento e técnicas de memória virtual como: paginação e segmentação, incluindo conceitos relacionados, como fragmentação, MMU (Memory Managment Unit) e TLB (Translation Lookaside Buffer).</li>
        </ul>
    </p>
    <h4>Sistema operacional</h4>
    <ul>
        <li>gerencia recursos do computador (CPU, E/S, memória)</li>
        <li>controla execução de processos (programas em execução) com auxílio de:</li>
            <ul>
                <li>registradores</li>
                <li>circuitos</li>
            </ul>
        <li>fornece uma interface mais simples para o usuário (abstração sem linha de comando)</li>
        <li>atua como uma camada entre o hardware e o usuário do sistema</li>  
    </ul>
    <h4>Gerenciamento de recursos</h4>
    <ul>
        <li>o SO direciona o processador e memória no uso dos recursos do sistema para:</li>
            <ul>
                <li>escalonar processos (escolher qual será processado)</li>
                    <ul>
                        <li>escalonador (scheduler) &rarr; seleciona (via algoritmo e hardware) os processos mais viáveis para execução</li>
                            <ul>
                                <li>escalonador de 2 níveis &rarr; o processo que tem menos tempo é colocado primeiro na RAM. Os demais ficam alocados na memória secundária</li>
                                <li>estados dos processos</li>
                                    <ul>
                                        <li>novo &rarr; quando é criado pelo usuário</li>
                                        <li>pronto &rarr; para ser executado</li>
                                        <li>executando &rarr; sendo processado pela CPU</li>
                                        <li>esperando &rarr; suspenso/aguardando dados ou informações de outro processos</li>
                                        <li>saída &rarr; terminado e destruído pelo SO</li>
                                    </ul>
                                <li>tipos de escalonamento</li>
                                    <ul>
                                        <li>curto prazo &rarr; qual processo será executado</li>
                                        <li>médio prazo &rarr; qual processo parcial será executado. Já está na RAM e coloca no Swap</li>
                                        <li>longo prazo &rarr; adicionar processo ao conjunto de processos a ser executado</li>
                                        <li>E/S &rarr; qual solicitação de E/S pendente será tratada</li>
                                    </ul>
                                <li>técnicas de escalonamento &rarr; justiça, políticas estabelecidas e equilíbrio (tudo operando)</li>
                                    <ul>
                                        <li>FIFO &rarr; primeiro que entra, primeiro que sai</li>
                                        <li>SJF (shortest job first) &rarr; mais curto primeiro</li>
                                        <li>RR (round robin) &rarr;</li>
                                        <li>múltiplas filas &rarr;</li>
                                        <li>loteria &rarr; distribui tokens randômicos. O sorteado será processado.</li>
                                        <li>fair-share &rarr; escalona considerando quem criou o processo (fração por usuário)</li>
                                    </ul>
                                <li>processos e threads &rarr; quebra dos processos</li>
                                    <ul>
                                        <li>cada thread pode ser executada em paralelo</li>
                                        <li>implementa a ideia de concorrência interna (ex. processador de texto)</li>
                                        <li>agiliza a programação e uso da CPU</li>
                                        <li>reduz ociosidade da CPU</li>
                                        <li>os threads também são escalonáveis</li>
                                        <li>não podem ser escalonados para serem executados em multiprocessadores</li>
                                    </ul>
                            </ul>
                        <li>compartilhar tempo &rarr; O SO determina quais processos devem ser executados pelo processador</li>
                            <ul>
                                <li>evita a ociosidade do processador</li>
                                <li>afeta o desempenho do sistema e satisfação do usuário</li>
                            </ul>
                    </ul>
            </ul>
    </ul>
    <h4>Gerenciamento de memória</h4>
        <ul>
            <li>feito pelo SO</li>
            <li>é um conjunto de memórias: registradores, cache, RAM, secundárias, fita magnética. <code>&lt; capacidade = &lt; tempo acesso</code></li>
            <li>utiliza técnicas para tornar a memória mais eficiente</li>
            <li>monoprogramação &rarr; único processo executando no sistema por vez. Usada em antigos mainframes, antigos computadores e nos dispositivos handhelds, como tablets e smartphones</li>
            <li>multiprogramação &rarr; mais de um processo executando no sistema por vez</li>
                <ul>
                    <li>causa fragmentação</li>
                    <li>particiona a RAM para manter os processos das seguintes maneiras:</li>
                        <ul>
                            <li>fixo &rarr; alocação estática. Geralmente iniciadas no boot da máquina</li>
                            <li>variável &rarr; alocação dinâmica em diferentes partições sob demanda</li>
                        </ul>
                    <li>cada partição tem 2 registradores &rarr; base e limite (para os processos não invadirem espaço de outro)</li>
                </ul>
            <li>memória virtual &rarr; técnica para acessar memória secundária quase equivalente à RAM. Seus princípios são:</li>
                <ul>
                    <li>localidade &rarr; espacial e temporal (a informação mais utilizada fica na RAM e o restante na secundária)</li>
                    <li>mapeamento &rarr; traduzir endereços em <mark>MMU</mark> (memory management unit - é um hardware)</li>
                        <ul>
                            <li><mark>é um dispositivo de hardware</mark></li>
                            <li>tradução do endereçamento lógico para físico</li>
                            <li>conhece as delimitações de endereçamento para o SO e o espaço vago</li>
                        </ul>
                    <li>funcionamento automático &rarr; abstrai para que o programador não precise se preocupar com isso</li>
                    <li>expansão dos níveis como uma memória cache &rarr; funciona como uma cache entre RAM e secundária</li>
                    <li>não é toda utilizada pela memória fisica</li>
                    <li>a capacidade é definida pelos limites de endereçamento (não pode invadir espaço delimitado para o SO)</li>
                    <li>vantagens da MV:</li>
                        <ul>
                            <li>pode ser maior que a RAM</li>
                            <li>permite que vários programas rodem simultaneamente</li>
                            <li>permite que cada programa tenha seu próprio espaço de endereçamento virtual</li>
                            <li>permite compartilhar memória física ou periféricos entre diferentes processos</li>
                            <li>traduz faixa de endereços virtuais de vários processos para uma mesma faixa de endereços físicos (continuidade de memória) o que acelera o acesso e evita problemas de segurança</li>
                        </ul>
                    <li>técnicas de MV</li>
                        <ul>
                            <li>paginação</li>
                                <ul>
                                    <li>quebra o tamanho do processo em páginas de tamanho fixo (&cong;4kb)</li>
                                    <li>o endereçamento virutal é dividido em páginas virtuais</li>
                                    <li>mistura os tipos de dados na mesma página</li>
                                    <li>funciona como os blocos na memória cache</li>
                                    <li>quanto menores forem as páginas maiores serão as quantidades de endereços e maior custo de mapeamento das páginas (causando overhead no sistema, vulgo HD 100%)</li>
                                </ul>
                            <li>segmentação</li>
                                <ul>
                                    <li>utiliza a quebra das páginas em blocos de tamanhos variados</li>
                                    <li>divide os blocos por tipos (texto, dados etc) para cada segmento</li>
                                </ul>
                        </ul>
                    <li>conceitos de paginação</li>
                        <ul>
                            <li>página é uma unidade de tamanho fixo na memória secundária</li>
                            <li>na memória secundária é página. Na RAM é frame</li>
                            <li>tabela de página é o mapeamento página-frame correspondente (tabela mesmo)</li>
                            <li>cada processo tem sua tabela</li>
                        </ul>
                    <li>endereçamento de página</li>
                        <ul>
                            <li>bit de validade &rarr; indica se a página está carregada na memória física</li>
                            <li>bit de proteção &rarr; indica se será feito leitura ou escrita</li>
                            <li>bit de modificação &rarr; se a página foi modificada ou não</li>
                            <li>bit de referência &rarr; se a página está sendo referenciada</li>
                            <li>bit de cache &rarr; indica se a memória cache deve ser habilitada</li>
                            <li>20 bits &rarr; # da página virtual na tabela de páginas</li>
                            <li>12 bits &rarr;> deslocamento de bits menos significativos</li>
                            <li>endereço físico composto por concatenção de:</li>
                                <ul>
                                    <li># da página física</li>
                                    <li>deslocamento</li>
                                </ul>                              
                        </ul>
                    <li>busca de endereço virtual</li>
                        <ul>
                            <li>sequencial &rarr; busca o endereço sequencialmente (pior caso se for o último)</li>
                            <li>binária &rarr; quebra ao meio sequencialmente (melhor que o sequencial)</li>
                            <li>ambas são lentas</li>
                                <ul>
                                    <li>causa overhead da memória</li>
                                    <li>ideal é o endereço virtual na tabela de páginas ser um índice</li>
                                    <li>a tabela de paginação se torna um arquivo grande</li>                         
                                </ul>
                            <li>paginação por demanda &rarr; as páginas são carregadas quando são referenciadas</li>
                        </ul>
                    <li>fragmentação interna</li>
                        <ul>
                            <li>quando sobram espaços internos na memória</li>
                            <li>páginas menores geram menos fragmentação porém mais buscas na tabela</li>
                            <li>páginas maiores geram o inverso</li>
                        </ul>
                    <li>segmentação</li>
                        <ul>
                            <li>permite lidar com blocos de tamanho variável e segmentos (não força o tamanho e adapta-se ao segmento)</li>
                            <li>segmentos de tamanhos desiguais não sobrecarregam a memória mas são mais complexos de implementar</li>
                        </ul>
                    <li>armazenamento da tabela de páginas</li>
                        <ul>
                            <li>no array de registradores da CPU</li>
                            <li>na memória cache (na MMU)</li>
                            <li>na RAM &rarr; uma tabela para a informação e outra para a memória. Causa overhead</li>
                        </ul>
                    <li><mark>TLB</mark> (Translation lookaside buffer)</li>
                        <ul>
                            <li>um cache em hardware que armazena as tabelas mais usadas num período de tempo</li>
                            <li>é um dicionário que recebe bits de entrada e fornece bits de saída (caso esteja armazenado nele)</li>
                                <ul>
                                    <li>bits de entrada</li>
                                        <ul>
                                            <li># página virtual</li>
                                            <li>identificador do processo</li>
                                        </ul>
                                    <li>bits de saída</li>
                                        <ul>
                                            <li>corresponde ao número de página virtual de cada processo composto por:</li>
                                                <ul>
                                                    <li># página física</li>
                                                    <li>bits de controle</li>
                                                </ul>
                                        </ul>
                                </ul>
                                <li>primeiro se busca na TLB e depois na tabela de páginas</li>
                        </ul>
                    
                </ul>
            <li>busca da memória ideal: grande&rarr;rápida&rarr;não volátil&rarr;barata (utopia que não existe)</li>
            <li>integração da memória</li>
                <ul>
                    <li>a abstração da memória é integrada e automática</li>
                    <li>cache e MV cooperam para implementar a abstração</li>
                    <li>o caminho mais rápido é se:</li>
                        <ul>
                            <li>o mapeamento estiver na TLB; e</li>
                            <li>a página estiver na RAM; e</li>
                            <li>o bloco estiver na cache</li>
                        </ul>
                </ul>
        </ul>
    <li>Glossário do livro:</li>
        <h4>Papéis do Sistema Operacional (SO)</h4>
        <ul>
            <li>Softwares aplicativos &rarr; Programas que nos ajudam a resolver problemas do mundo real</li>
            <li>Softwares de sistemas &rarr; Programas que gerenciam um sistema computacional e interagem com hardware</li>
            <li>Sistema operacional &rarr; Software de sistema que gerencia recursos computacionais e fornece uma interface para interação com o sistema</li>
            <li>Multiprogramação &rarr; A técnica de manter múltiplos programas em memória principal ao mesmo tempo, competindo pela CPU</li>
            <li>Gerenciamento de memória &rarr; O ato de manter registro de como e onde programas são carregados em memória principal</li>
            <li>Processo &rarr; A representação dinâmica de um programa durante execução</li>
            <li>Gerenciamento de processo &rarr; O ato de manter registro de informação para processos ativos</li>
            <li>Escalonamento de CPU &rarr; O ato de determinar qual processo em memória terá acesso à CPU, de modo que ele possa executar</li>
            <li>Tempo compartilhado &rarr; Um sistema no qual tempo de CPU é compartilhado entre múltiplos usuários interativos ao mesmo tempo</li>
            <li>Máquina virtual &rarr; A ilusão criada por um sistema de tempo compartilhado de que cada usuário possui uma máquina dedicada</li>
            <li>Grande porte &rarr; Um computador de grande porte, multiusuário, comumente associado aos primeiros sistemas de tempo compartilhado</li>
            <li>Terminal burro &rarr; monitor e um teclado que permitiam ao usuário acessar o computador de grande porte nos primeiros sistemas de tempo compartilhado</li>
            <li>Sistema de tempo real &rarr; Um sistema no qual tempo de resposta é crucial, dada a natureza do domínio de aplicação</li>
            <li>Tempo de resposta &rarr;O tempo decorrido entre receber um estímulo e produzir uma resposta</li>
        </ul>
        <h4>Gerenciamento de memória</h4>
            <ul>
                <li>Endereço lógico &rarr; Uma referência a um valor armazenado, relativa ao programa que faz a referência</li>
                <li>Endereço físico &rarr; Um endereço real no dispositivo de memória principal</li>
                <li>Ligação de endereço &rarr; O mapeamento de um endereço lógico em um endereço físico</li>
                <li>Gerenciamento de memória contígua única &rarr; A abordagem de gerenciamento de memória na qual um programa é carregado em uma área contígua de memória</li>
                    <ul>
                        <li>A vantagem da abordagem de gerenciamento de memória contígua única é que ela é simples de implementar e gerenciar</li>
                        <li>No entanto, é quase certo que ela desperdice tanto espaço de memória como tempo de CPU</li>
                        <li>É pouco provável que um programa aplicativo necessite de todo o espaço de memória não usado pelo sistema operacional e tempo de CPU é desperdiçado quando o programa tem que esperar por algum recurso</li>
                    </ul>
                <li>Gerenciamento de Memória Particionada</li>
                    <ul>
                        <li>Técnica de partição dinâmica &rarr; A técnica de gerenciamento de memória na qual a memória é dividida em partições conforme for necessário acomodar programas</li>
                        <li>Registrador base &rarr; Um registrador que mantém o endereço de início da partição corrente</li>
                        <li>Registrador de limites &rarr; Um registrador que mantém o tamanho da partição corrente</li>
                        <li>Compactação &rarr; Com partições dinâmicas, as tarefas podem ser rearranjadas na memória, de modo a criar uma única grande partição livre</li>
                    </ul>
                <li>Gerenciamento de Memória Paginada</li>
                    <ul>
                        <li>Técnica de memória paginada Uma técnica de gerenciamento de memória na qual processos são divididos em páginas de tamanho fixo e armazenados em quadros de memória quando carregados</li>
                        <li><mark>Frame</mark> (Quadro) &rarr; Uma parte de tamanho fixo de memória principal que guarda uma página de processo</li>
                        <li>Página &rarr; Uma parte de tamanho fixo de um processo que é armazenada em um quadro de memória</li>
                        <li>Tabela de mapeamento de páginas (<mark>TMP</mark>) &rarr; A tabela usada pelo sistema operacional para manter registro de relacionamentos página/quadro</li>
                        <li>Paginação sob demanda &rarr; Uma extensão ao gerenciamento de memória paginada na qual páginas são trazidas para memória apenas quando são referenciadas (sob demanda</li>
                        <li>Troca de página &rarr; Trazer uma página da memória secundária, possivelmente fazendo com que outra seja removida</li>
                        <li>Memória virtual &rarr; A ilusão de que não há restrição de tamanho de programa, já que um processo inteiro não precisa estar em memória ao mesmo tempo</li>
                        <li>Hiperpaginação &rarr; Processamento ineficiente causado por trocas constantes de páginas</li>
                    </ul>
            </ul>
        <h4>Gerenciamento de Processos</h4>
            <ul>
                <li>Estados de processo &rarr; Os estágios conceituais pelos quais um processo passa à medida que ele é gerenciado pelo sistema operacional</li>
                <li>Bloco de controle de processo (<mark>BCP</mark>) &rarr; A estrutura de dados usada pelo sistema operacional para gerenciar informação sobre um processo</li>
                <li>Chaveamento de contexto &rarr; A troca de informação de registrador que ocorre quando um processo é removido da CPU e outro entra em seu lugar</li>
                <li>Escalonamento de CPU</li>
                    <ul>
                        <li>Escalonamento não preemptivo &rarr; Escalonamento de CPU que ocorre quando o processo correntemente em execução cede a CPU voluntariamente</li>
                        <li>Escalonamento preemptivo &rarr; Escalonamento de CPU que ocorre quando o sistema operacional decide favorecer outro processo, interrompendo o processo atualmente em execução</li>
                        <li>Tempo de retorno &rarr; A métrica de escalonamento de CPU que mede o tempo decorrido entre a chegada do processo ao estado pronto e sua conclusão final</li>
                        <li>Page fault é a falta de página, quando a página não foi carregada na memória principal e está referenciada</li>
                    </ul>
            </ul>
    <hr>
    <h2>Semana 4</h2>
    <p>
        Nesta semana, em busca do aprimoramento de performance de processamento de sistemas computacionais, você conhecerá paralelismo com base em diferentes estratégias de implantação, seja em instruções de software ou em hardwares, em arquiteturas paralelas e arquiteturas avançadas. Em software, pipeline em instrução manipula a concorrência de recursos para realização de ações em um único processador. Multiprocessadores podem compartilhar memória e serem reunidos em um mesmo chip ou simplesmente multiplicar CPUs que se comunicam. Placas extras de CPU podem funcionar como coprocessadores com capacidade de processamento adicional para, por exemplo, processamento multimídia ou criptografia. Para super desempenho, pode-se replicar computadores inteiros funcionando juntos de maneira eficiente. Multicomputadores ou computadores em cluster interligam muitos processadores em um grande sistema ou mesmo grids conectando organizações inteiras. Para todos os casos ocorrem problemas que precisam ser resolvidos por estratégias de sistemas computacionais. <br> <br>

        Habilidades e competências:

        <ul>
            <li>Entender as arquiteturas paralelas e suas classes ou tipos;</li>
            <li>Entender multiprocessadores e multicomputadores com suas características, diferenças e exemplos;</li>
            <li>Aprender o funcionamento de pipeline de instrução, sua estratégia de implementação, problemas e soluções.</li>
        </ul>
    </p>
    <h4>Arquitetura paralela e avançadas</h4>
            <ul>
                <li>estruturua hierárquica multicore</li>
                    <ul>
                        <li>cada processador possui mais de um core</li>
                        <li>cada core possui memória cache e ULA</li>
                    </ul>
                <li>ciclo de instrução</li>
                    <ul>
                        <li>o processador executa instruções (em LM) em determinado clock</li>
                        <li>o ciclo é a sequência de ações para realizar cada instrução em LM</li>
                        <li>as instruções são carregadas na RAM pelo SO</li>
                        <li>se repete indefinidamente até que:</li>
                            <ul>
                                <li>o sistema seja desligado; ou</li>
                                <li>ocorra algum erro; ou</li>
                                <li>encontre instrução de parada</li>
                            </ul>
                        <li>a CPU executa as instruções definidas pelo programa em execução</li>
                        <code>
                            start <br>
                                                        busca de instrução;<br>
                                                        decodificação da instrução;<br>
                                                        cálculo de endereço de operando;<br>
                                                        busca de operando;<br>
                                                        execução da instrução;<br>
                                                        cálculo de endereço do resultado;<br>
                                                        verificação de interrupção;<br>
                                                        se interrupção, então tratamento de interrupção;<br>
                                                        cálculo de endereço da próxima instrução;<br>
                                                        volta para busca de instrução;<br>
                                                    end
                        </code>
                    </ul>
                <li>funções básicas da CPU</li>
                    <ul>
                        <li>processamento &rarr; processar (executar operações)</li>
                        <li>controlar</li>
                            <ul>
                                <li>busca, interpretação e controle da execução das instruções</li>
                                <li>demais componentes do sistema (memória, E/S etc)</li>
                            </ul>
                    </ul>
                <li>processo serial</li>
                    <ul>
                        <li>execução sequencial do ciclo de instrução</li>
                        <li>é lento e pouco eficiente</li>
                    </ul>
                <li>paralelismo</li>
                    <ul>
                        <li>fazer mais de uma instrução por ciclo</li>
                        <li>executa em menor tempo o ciclo completo</li>
                        <li>pode ser implementado por hardware (processador) ou software (envio de instruções)</li>
                        <li>modalidades de paralelismo</li>
                            <ul>
                                <li>software &rarr; mais instruções por ciclo</li>
                                <li>hardware &rarr; mais de um processador atuando no mesmo ciclo para várias instruções</li>
                            </ul>
                        <li>tipos de programação de paralelismo:</li>
                            <ul>
                                <li>sequencial</li>
                                <li>concorrente &rarr; escalonamento do tempo do servidor para atender vários clientes</li>
                                <li>paralela &rarr; vários servidores atendendo vários clientes no mesmo intervalo de tempo</li>
                            </ul>
                        <li>arquiteturas paralelas</li>
                            <ul>
                                <li>classificação de Flynn (1972) &rarr; unicidade e multiplicidade do fluxo de dados e instruções</li>
                                    <ul>
                                        <li>SISD &rarr; instruções e dados simples</li>
                                            <ul>
                                                <li>fluxo único de instrução e dado</li>
                                                <li>seriais de Von Neumann</li>
                                                <li>são os computadores convencionais</li>
                                                <li>instruções executadas serialmente (porém pode ser implementado o pipeline)</li>
                                            </ul>
                                        <li>SIMD &rarr; instrução simples e múltiplos dados (faz tarefa repetitiva. Ex. data minning)</li>
                                            <ul>
                                                <li>fluxo único de instruções e fluxo múltiplo de dados</li>
                                                <li>a mesma instrução agindo em muitos dados</li>
                                                <li>unidade de controle única envia instruções para processadores matriciais ou paralelos</li>
                                                <li>cada processador recebe a mesma instrução mas atua sobre dados específicos</li>
                                                <li>usado em processadores vetoriais</li>
                                            </ul>
                                        <li>MISD &rarr; múltiplas instruções e dados simples (<mark>é mais raro</mark>)</li>
                                            <ul>
                                                <li>fluxo múltiplo de instruções e fluxo único de dados</li>
                                                <li>vários processadores que recebem instruções distintas</li>
                                                <li>operam sob os mesmos dados</li>
                                                <li>usado em algoritmo de criptografia</li>
                                            </ul>
                                        <li>MIMD &rarr; múltiplos dados e instruções</li>
                                            <ul>
                                                <li>vários processadores controlados por UCs distintas</li>
                                                <li>as instruções são diferentes para cada processador</li>
                                                <li>operam sobre dados diferentes</li>
                                                <li>podem ser síncronos ou assíncronos</li>
                                                <li>multiprocessadores (memória compartilhada)</li>
                                                <li>multicomputadores (memória distribuída)</li>
                                                <li>a sincronização entre tarefas é feita via escrita/leitura de memória compartilhada</li>
                                                <li>o usuário é responsável pela especificação e programação</li>
                                                <li>permitem declarações de variáveis compartilhadas</li>
                                                <li>permitem seções paralelas de código</li>
                                                <li>o compilador gera o código executável</li>
                                                <li>threads &rarr; código de alto nível que permite acesso a localidades compartilhadas em processadores individuais</li>
                                                <li>multiprocessador <mark>NUMA</mark> (NonUniform Memory Access) &rarr; acesso não uniforme à memória</li>
                                                    <ul>
                                                        <li>endereçamento único para todas as CPUs</li>
                                                        <li>acesso à memória local mais rapido que remoto</li>
                                                        <li>3 características que a distinguem:</li>
                                                        <ul>
                                                            <li>espaço de endereço visível a todas às CPUs</li>
                                                            <li>acesso remoto à memória com instruções Load e Store</li>
                                                            <li>sim, eu sei...cadê a terceira característica?</li>
                                                        </ul>
                                                    <li>multicomputadores (cluster e supercomputador) &rarr; memória distribuída</li>
                                                        <ul>
                                                            <li>tarefas se comunicam por troca de mensagens</li>
                                                            <li>sincronização feita por meio dessas trocas</li>
                                                            <li>a programação requer software especial (bibliotecas)</li>
                                                            <li>permite portabilidade de aplicações entre plataformas</li>
                                                            <li>usam programação com:</li>
                                                                <ul>
                                                                    <li>bibliotecas de rotinas &rarr; passagem de mensagens ligadas a programas sequenciais</li>
                                                                    <li>problema dividido em tarefas que se comunicam</li>
                                                                    <li>computadores programados por protocolos independentes de linguagem</li>
                                                                    <li>exemplos</li>
                                                                        <ul>
                                                                            <li>Massive Paralel Process(<mark>MPP</mark>) &rarr; máquinas conectadas por rede de alta velocidade</li>
                                                                                <ul>
                                                                                    <li>boa escalabilidade</li>
                                                                                    <li>podem ser uma grande quantidade de máquinas</li>
                                                                                    <li>complicadas de programar</li>
                                                                                    <li>alto custo</li>
                                                                                    <li>tratamento de enormes transações por segundo</li>
                                                                                    <li><mark>Intel Paragon</mark></li>
                                                                                    <li>precisam de:</li>
                                                                                        <ul>
                                                                                            <li>enorme capacidade tolerância a falha</li>
                                                                                            <li>enorme capacidade de E/S</li>
                                                                                        </ul>
                                                                                </ul>
                                                                            <li>Cluster of Workstation (<mark>COW-GRID</mark>)</li>
                                                                                <ul>
                                                                                    <li>estações de trabalho conectadas por rede local</li>
                                                                                    <li>baixo custo</li>
                                                                                    <li>boa relação custo/benefício</li>
                                                                                    <li>cluster centralizado &rarr; montado com máquinas homogêneas</li>
                                                                                    <li>cluster descentralizado &rarr; estações de trabalho heterogêneas (com periféricos)</li>
                                                                                    <li>conectados por 	LAN &rarr; precisa se preocupar com topologias de rede</li>
                                                                                </ul>
                                                                        </ul>
                                                                </ul>
                                                        </ul>
                                                    <li>multiprocessadores e multicomputadores</li>
                                                        <ul>
                                                            <li>semelhanças:</li>
                                                                <ul>
                                                                    <li>são semelhantes quando se trata de interconexão</li>
                                                                    <li>ambos trocam mensagem</li>
                                                                    <li>MPs enviam mensagens quando precisam ler ou escrever dados</li>
                                                                    <li>no MC a troca de mensagem ocorre via comunicação e sincronização</li>
                                                                </ul>
                                                            <li>diferenças:</li>
                                                                <ul>
                                                                    <li>presença ou ausência de memória compartilhada</li>
                                                                    <li>MP &rarr;   compartilha memória (mapeado em endereço virtual de memória)</li>
                                                                    <li>MC &rarr; cada computador tem sua própria memória</li>
                                                                </ul>
                                                        </ul>
                                                    </ul>
                                            </ul>
                                    </ul>
                                <li>classificação de Duncan (1990) &rarr; cadê? só tocou no assunto</li>
                            </ul>
                    </ul>
            </ul>
    <h4>Pipeline</h4>
            <ul>
                <li>proporciona melhor desempenho</li>
                <li>circuitos mais rápidos</li>
                <li>processador com múltiplos registradores e memória cache</li>
                <li>tipos de pipeline:</li>
                    <ul>
                        <li>instrução</li>
                            <ul>
                                <li>várias instruções realizadas simultaneamente por ciclo de clock</li>
                                <li>em estágios diferentes</li>
                                <li>há divisão da CPU em partes distintas (cada parte executa uma ação)</li>
                                <li>aceita novas entradas antes de concluir as que estão sendo processadas</li>
                            </ul>
                    </ul>
                <li>estágios de pipeline (mesmo tempo para cada)</li>
                    <code>
                        start <br>
			                fetch instruction (FI) &rarr; busca instrução <br>
			                decode instruction (DI) &rarr; decodifica <br>
			                cálculo de operandos (CO) &rarr; <br>
			                fetch operands (FO) &rarr;> busca operandos <br>
			                execute instruction (EI) &rarr; execução da instrução <br>
			                write operands (WO) &rarr; escrita de operando <br>
		                end
                    </code>
                    <ul>
                        <li>se os tempos de duração de cada instrução não for igual haverá espera ou bolha</li>
                        <li>instrução de desvio pode danificar as buscas de instruções (como na interrupção)</li>
                        <li>quanto maior o número de estágios maior será a taxa de execução</li>
                        <li>situações que atrapalham:</li>
                            <ul>
                                <li>muito esforço para movimentar dados desacelera o tempo total de execução</li>
                                <li>a lógica de controle de passagem de estágios é mais complexa do que em estágios controlados</li>
                            </ul>
                        <li>entre 6 e 9 estágios é o ideal para ganho de performance no pipeline</li>
                        <li>entre 10 e 30 instruções por estágio também é o ideal</li>
                    </ul>
                <li>desempenho:</li>
                    <ul>
                        <li>o tempo de execução de cada instrução é o mesmo sem pipeline</li>
                        <li>latência é o tempo de execução de cada instrução</li>
                        <li>a tarefa mais lenta limita a taxa de inserção de tarefas no pipeline</li>
                        <li>o tempo total de várias instruções é menor</li>
                        <li>a saída (<mark>throughput</mark>) pode aumentar. A quantidade de instruções executadas é maior</li>
                        <li>a meta é aumentar a produtividade</li>
                        <li>o pipeline tem que estar sempre cheio de tarefas para o melhor desempenho</li>
                    </ul>
                <li><mark>hazards</mark> (prejuízos/conflitos)</li>
                    <ul>
                        <li>bolhas &rarr; situação que afeta o desempenho do pipeline. Precisa parar e esperar outra instrução</li>
                            <ul>
                                <li>tipos de bolhas:</li>
                                    <ul>
                                        <li>recurso (estrutural) &rarr; 2 ou mais instruções utilizando o mesmo recurso</li>
                                        <li>dados &rarr; 2 instruções querem acessar o mesmo operando ao mesmo tempo</li>
                                        <li>desvio &rarr; necessidade de tomar decisão com o resultado da instrução enquanto outra está sendo executada. Soluciona-se com busca antecipada do desvio deixado no buffer</li>
                                    </ul>
                            </ul>
                        <li>a busca de instruções na memória é um gargalo de tempo</li>
                        <li>evita-se esse problema buscando antecipadamente as instruções na memória</li>
                        <li>armazena essas instruções em buffer de busca antecipada</li>
                            <ul>
                                <li><mark>prefetch</mark> &rarr; busca avançada. Aproveita o ciclo para obter a próxima instrução</li>
                                    <ul>
                                        <li>requer mais registradores</li>
                                        <li>o tempo de leitura aumenta</li>
                                        <li>se não ocorrer o desvio a instrução será descartada</li>
                                        <li><mark>NUNCA MAIS APAGUE CONTEÚDO DA PASTA PREFETCH DO WINDOWS</mark></li>
                                    </ul>
                            </ul>
                        <li>busca-se primeiro neste buffer antes de ir até a memória</li>
                    </ul>
            </ul>
    <hr>
    <h2>Semana 5</h2>
    <p>
        Nesta semana, você descobrirá comandos e estruturas de dados da Linguagem C para simular processos de paginação e particionamento de memória. A paginação é uma técnica de Memória Virtual que “quebra” os processos em páginas e cria um endereçamento virtual para aprimorar o tempo de busca de informações em disco secundário, para carregar em memória principal. Para trabalhar a hierarquia de memórias, a multiprogramação aplica basicamente duas estratégias de divisão da memória principal: particionamento fixo da memória e particionamento dinâmico. O particionamento de memória também objetiva aprimorar o uso das memórias de um computador. Usando os conceitos no início desta semana, você acompanhará simulações de particionamento fixo e paginação e será desafiado a aplicar seus conhecimentos em novas simulações de arquitetura e organização de sistemas computacionais. <br> <br>

        Habilidades e competências:

        <ul>
            <li>Aprender comandos básicos, ponteiros e estruturas em Linguagem C;</li>
            <li>Entender duas importantes estratégias de arquitetura e organização de sistemas computacionais a partir da simulação de paginação e particionamento fixo.</li>
        </ul>
    </p>
    <h4>Linguagem C</h4>
            <ul>
                <li>estrutura básica:</li>
                    <ul>
                        <li>bibliotecas de funções (includes e macros)</li>
                        <li>declarações globais (funções e variáveis)</li>
                        <li>definição das funções</li>
                        <li>programa principal (função main)</li>
                        <code>
                                main() {/* begin */ <br>
                                        /* end */}
                        </code>
                    </ul>
                <li>ponteiros</li>
                    <ul>
                        <li>variável que contém um endereço de  memória (posição de outra variável na memória)</li>
                        <li>diz-se que um ponteiro aponta para uma variável</li>
                        <li>são usados para alocação dinâmica de memória</li>
                        <li>pode aumentar a eficiência de certas rotinas</li>
                        <li>fornecem meios para funções modificarem seus argumentos</li>
                        <li>declarado com * antes do nome da variável. Ex.: int *p; char *p1; float *pf1;</li>
                        <li>os operadores de ponteiro (* &) tem precedência sobre todos os operadores aritméticos</li>
                        <li>podem apontar para qualquer posição de memória</li>
                        <li>usa-se geralmente para 3 operações:</li>
                            <ul>
                                <li>atribuição &rarr; um ponteiro receber o endereço apontado por outro ponteiro, ambos apontando para o mesmo endereço</li>
                                <li>aritmética &rarr; apenas adição e subtração. Incrementa ou decrementa o endereço. Ex.:</li>
                                <code>
                                    int *p, num=1, num2; <br>
                                    p = & num; <br>
                                    num = *p + 1; // o valor apontado por p + 1 = 2 <br>num2 = *& num; // recebe o valor do endereço apontado por num = 2
                                </code>
                                <li>comparação &rarr; compara-se a posição de memória. Ex.:</li>
                                <code>
                                    int *p1, *p2, x=10; <br>
                                    p1 = &x; // recebe o endereço de x <br>
                                    p2 = p1; // recebe o endereço contido em p1 (que aponta para x) <br>
                                    if (p1 == p2)	// dará verdadeiro
                                </code>
                            </ul>
                        <li>operador &</li>
                            <ul>
                                <li>é um operador unário (operador endereço e só modifica uma variável)</li>
                                <li>devolve o endereço de memória do seu operando</li>
                                <li>mais usado na inicialização do ponteiro. Ex.:</li>
                                <code>
                                    int *p, acm = 35; <br>
                                    p = &acm; // p recebe o endereço de acm <br>
                                    p = 0 = NULL (p não aponta mais para acm)
                                </code>
                            </ul>
                        <li>operador *</li>
                            <ul>
                                <li>também é unário</li>
                                <li>retorna o valor da variável apontada. Ex.:</li>
                                <code>
                                    int *p, q, acm = 35; <br>
                                    p = &acm; <br>
                                    q = *p; // q agora recebe o valor 35 (e não o mesmo endereço de acm)
                                </code>
                            </ul>
                        <li>estruturas</li>
                            <ul>
                                <li>composição de tipos de dados diferentes (ou não) na mesma estrutura</li>
                                <li>as variáveis que compõe essa estrutura são chamadas de elementos</li>
                                <li>não cria um novo tipo de dado, só os agrupa em uma estrutura</li>
                                <li>tem que ser inserido após os includes</li>
                                <li>uma estrutura pode ter campos como outra estrutura. Ex.:</li>
                                <code>
                                    struct ponto { <br>
                                        int x, y; <br>
                                    }; <br>
                                    struct retangulo { <br>
                                        struct ponto p1, p2; <br>
                                    }ret; <br> <br>
                                    ret.p1.x=10;
                                </code>
                            </ul>
                        <li>formato:</li>
                            <ul>
                                <li>typedef tipo nome;</li>
                                <li>onde tipo &rarr; int, float, double, char etc</li>
                                <li>nome &rarr; identificador válido em C</li>
                            </ul>
                    </ul>
                <li>simulação de paginação e particionamento fixo</li>
                    <ul>
                        <li>paginação</li>
                            <ul>
                                <li>quebra de processos em páginas que são mapeadas em frames na RAM</li>
                                <li>em processadores Intel, a MMU faz esse mapeamento</li>
                                <li>a alocação de memória e feita por página</li>
                                <li>o bit de validade indica se a página está carregada na RAM (1 para sim)</li>
                                <li>são páginas virtuais com endereçamento virtual</li>
                                <li>misturam tipos de dados</li>
                                <li>tem tamanho fixo na memória secundária</li>
                                <li>na RAM são chamadas de frames</li>
                                <li>a tabela de página mapeia uma página com um frame</li>
                                <li>cada processo tem sua tabela de páginas</li>
                            </ul>
                        <li>particionamento</li>
                            <ul>
                                <li>particionamento fixo com mesmo tamanho</li>
                                <li>particionamento fixo com tamanho variável</li>
                                <li>particionamento variável ou dinâmico</li>
                                <li>hierarquia de memórias</li>
                                    <ul>
                                        <li>monoprogramação &rarr; único processo sendo executado no processador</li>
                                        <li>multiprogromação &rarr; vários processos compartilhando o processador</li>
                                    </ul>
                            </ul>
                    </ul>
            </ul>
    <hr>
    <h2>Semana 6</h2>
    <p>
        Nesta semana, você conhecerá dois tipos de linguagens que tornam possível um computador entender o que escrevemos em linguagem de alto nível como Ruby, Java, Phyton, C etc. Essas linguagens de comunicação mais diretas com o computador são chamadas de linguagem de baixo nível. Na verdade, elas são chamadas assim porque têm menor nível de abstração do que as linguagens de programação tradicionais. Elas manipulam representações simbólicas (SUB, ADD, MUL) e operam com registradores (EAX, EDX), no caso da linguagem de montagem, e números binários ou hexadecimais, no caso da linguagem de máquina. Quando queremos otimizar recursos dos sistemas computacionais, ficamos impedidos, na maioria das situações, com os recursos disponibilizados por linguagens de alto nível. Nesses casos, precisamos “conversar” com o sistema operacional, via interrupções ou chamadas de sistema, e inclusive manipular comandos de linguagem de montagem como Assembly. Por essas razões, essa semana pretendemos desenvolver as seguintes: <br> <br>

        Habilidades e competências:

        <ul>
            <li>Compreender as diferenças, as características, os propósitos de uso da linguagem de montagem e da linguagem de máquina;</li>
            <li>Entender a importância das diferentes linguagens (alto nível, de montagem, de máquina) no processo de modelagem de software;</li>
            <li>Conhecer os conceitos de chamada de sistema e tratamentos de interrupção.</li>
        </ul>
    </p>
    <h4>Chamadas de sistemas (<mark>SysCalls</mark>)</h4>
            <ul>
                <li>quando um programa solicita serviço do SO</li>
                <li>quando uma instrução precisa realizar uma instrução privilegiada (como imprimir um arquivo)</li>
                <li>chama um módulo do SO para acessar na memória secundária</li>
                <li>é toda vez que precisa da ajuda do SO para acessar algum recurso</li>
                <li>são realizadas por instruções <mark>Traps</mark> (interrupções de software)</li>
                <li>a aplicação para sua execução até receber resposta do SO e volta no mesmo ponto que parou</li>
                <li>interfaces das SysCalls</li>
                    <ul>
                        <li>interface para esconder a complexidade</li>
                        <li>interface de programação</li>
                        <li>escrita em linguagem de alto nível (C/C++/Java)</li>
                        <li>utilizam uma Application Program Interface (API) que encapsula o acesso direto ao SO</li>
                            <ul>
                                <li>as três principais são: Win32 (Windows), Posix (Unix), Java API (JVM)</li>
                                <li>motivos para usar API:</li>
                                    <ul>
                                        <li>portabilidade &rarr; para independer de plataforma</li>
                                        <li>esconder complexidade</li>
                                        <li>otimizar desempenho &rarr; com acréscimo de funcionalidades</li>
                                    </ul>
                            </ul>
                    </ul>
            </ul>
    <h4>Interrupções</h4>
            <ul>
                <li>é a base para a implementação do paralelismo</li>
                <li>permite que o hardware informe a CPU quando algo precisa ser feito</li>
                <li>são mecanismos pelo qual outros módulos interrompem o processamento da CPU</li>
                <li>são de grande maioria assíncronos (com exceção dos traps)</li>
                <li>permite aos periféricos sincronizarem suas operações com a CPU (evita desperdício de tempo da CPU)</li>
                <li>informa eventos como:</li>
                    <ul>
                        <li>traps &rarr; interrupção de programa</li>
                        <li>escalonar processos &rarr; interrupção de temporização</li>
                        <li>falha de hardware &rarr; possível falta de energia</li>
                        <li>escrita em disco &rarr; interrupção de E/S</li>
                        <li>chegada de dado pela rede</li>
                        <li>tecla pressionada</li>
                        <li>clique de mouse</li>
                    </ul>
                <li>existem dois tipos:</li>
                    <ul>
                        <li>de software &rarr; ocorre no sistema</li>
                            <ul>
                                <li>interrupção x traps</li>
                                    <ul>
                                        <li>é uma interrupção de programa</li>
                                        <li>são consequência de alguma instrução executada no processador</li>
                                        <li>ex.: divisão por zero</li>
                                        <li>o programa não tem como prosseguir pois ocorreu uma exceção</li>
                                        <li>são síncronas</li>
                                        <table>
                                            <tr>
                                                <th>interrupção</th>
                                                <th>traps</th>
                                            </tr>
                                                <tr>
                                                    <td>evento externo ao processador</td>
                                                    <td>evento vindo de dentro do processador</td>
                                                </tr>
                                                <tr>
                                                    <td>gerada por dispositivos</td>
                                                    <td>gerada pela aplicação</td>
                                                </tr>
                                                <tr>
                                                    <td>pode não estar relacionada ao processo corrente</td>
                                                    <td>causada pelo processo corrente em execução</td>
                                                </tr>
                                        </table>
                                    </ul>
                            </ul>
                        <li>de hardware &rarr; ocorre fora do sistema</li>
                            <ul>
                                <li>para indicar overflow ou acessos a regiões de memória não permitidas</li>
                                <li>situações em que o programa não teria como prosseguir</li>
                                <li>o hardware sinaliza um interrupção e passa o controle para o tratador</li>
                                <li>tipicamente termina a execução do programa</li>
                                <li>interrupção de relógio:</li>
                                    <ul>
                                        <li>é comum de hardware</li>
                                        <li>atribui quotas de tempos de execução para cada processo</li>
                                        <li>muda o status do processo se o tempo dele se esgotou (de executando para suspenso)</li>
                                    </ul>
                            </ul>
                    </ul>
                <li>tratamento de interrupção</li>
                    <ul>
                        <li>é um programa que determina a natureza da interrupção</li>
                        <li>realiza o tratamento adequado</li>
                        <li>o controle é transferido para o tratador após salvar algumas informações</li>
                        <li>é parte do SO</li>
                        <li>quando ocore interrupção a CPU para de processar o programa</li>
                        <li>a CPU passa a executar o código chamado de tratador de interrupção</li>
                        <li>após tratar a interrupção a CPU volta a processar o programa interrompido</li>
                        <li>feito por bloco especial de código</li>
                        <li>é chamado de rotina de serviço ou <mark>ISR</mark></li>
                        <li>os handlers de interrupção são iniciados por interrupção de hardware, software ou exceções de software</li>
                        <li>usado para implementar drivers de dispositivo ou transições entre modos protegidos como SysCalls</li>
                        <li>função do tratador:</li>
                            <ul>
                                <li>saber qual dispositivo lançou a IRQ</li>
                                <li>saber o endereço inicial da rotina que tratará a IRQ</li>
                            </ul>
                        <li>fluxo de controle:</li>
                            <ul>
                                <li>é uma chamada de rotina do programa em execução</li>
                                <li>é assíncrono (entre o programa interrompido e o tratador)</li>
                                <li>é síncrono no caso de Traps</li>
                            </ul>
                    </ul>
                <li>suporte de hardware</li>
                    <ul>
                        <li>detecta a interrupção</li>
                        <li>aguarda o fim da execução da IRQ</li>
                        <li>aciona o tratador</li>
                        <li>salva a condição antes da execução da IRQ (no contador de programa)</li>                        
                    </ul>
            </ul>
    <h4>Linguagem de montagem (<mark>Assembly</mark>)</h4>
            <ul>
                <li>forma do computador entender as instruções dadas pelos programas</li>
                <li>usa nomes simbólicos (<mark>mnemônicos</mark>)</li>
                <li>atribui nomes a posições específicas da memória (como a linguagem Assembly)</li>
                <li>composta por instruções que não são executadas diretamente mas ajudam a produzir o código de máquina</li>
                <li>cada arquitetura tem uma <mark>ISA</mark> (Instruction Set of Arch, conjunto de instruções da arquitetura)</li>
                <li>todas as máquinas tem Assembly</li>
                <li>utiliza nomes como: ADD, SUB e MUL</li>
                <li>para que usar Assembly?</li>
                    <ul>
                        <li>demora mais que linguagens de alto nível</li>
                        <li>leva mais tempo para depurar</li>
                        <li>a manutenção é mais complicada</li>
                        <li>é mais fácil do que a LM</li>
                        <li>usada em sistemas embarcados, smartcards, drivers de dispositivos, bibliotecas de manipulação de strings, rotinas de BIOS, controladores de disco etc (acesso completo ao hardware)</li>
                        <li>localizar erros</li>
                        <li>criar compiladores, depuradores e ferramentas de desenvolvimento</li>
                        <li>manipular sistemas embarcados</li>
                        <li>construir drivers para hardware</li>
                        <li>acessar instruções inacessíveis por linguagens de alto nível</li>
                        <li>otimizar tamanho de código para caber em cache</li>
                        <li>otimizar desempenho de código</li>
                        <li>compatibilizar bibliotecas de funções com compiladores e SOs</li>
                    </ul>
                <li>estrutura de sentença de Assembly é composta por:</li>
                    <ul>
                        <li>rótulo &rarr; opcional</li>
                            <ul>
                                <li>é identificador da instrução/constante</li>
                                <li>pode ser usado como endereço ou dado no código</li>
                                <li>são usados em instruções de desvio (frequentemente). Ex.:</li>
                                    <code>
                                        L2: SUB EAX, EDX (L2 é o identificador, SUB é a operação, EAX e EDX são os operandos). equivalente a: EAX = EAX - EDX <br>
                                        JG L2	(JG é a operação Pular e L2 fazendo um laço até L2 ser menor que 0)
                                    </code>
                                <li>possibilita localizar mais facilmente a posição do programa</li>
                                <li>pode ser movido com facilidade</li>
                                <li>o Assembler mudará todas as referências de endereço quando o rótulo for mudado</li>
                                <li>facilita para o programador que não precisa recalcular endereços de memória</li>
                            </ul>
                        <li>mnemônico &rarr; nome do opcode (operação ou função) ou da diretiva</li>
                            <ul>
                                <li>serve para identificar a operação ou funçao</li>
                                <li>pode corresponder a uma instrução de máquina, diretiva do montador ou uma macro. Ex.: MOV, SUB</li>
                            </ul>
                        <li>operando(s) &rarr; servem para especificar dados necessários à operação</li>
                            <ul>
                                <li>podem ser zero ou mais de um operando</li>
                                <li>cada operando identifica um tipo de referência (valor imediato, registrador ou posição de memória)</li>
                                <li>Assembly fornece convenções para distinguir 3 tipos de referências de operando</li>
                                <li>indica o modo de endereçamento</li>
                            </ul>
                        <li>comentário &rarr; opcional</li>
                            <ul>
                                <li>começa com um caractere especial</li>
                                <li>sinaliza para o Assembler que o restante da linha é um comentário e deve ser ignorado</li>
                                <li>todas as linguagens de montagem permitem inserir comentários</li>
                                <li>podem estar no lado direito de um comando ou usar a linha inteira</li>
                            </ul>
                    </ul>
                <li>tipos de sentenças</li>
                    <ul>
                        <li>de comentário &rarr; inteiramente um comentário</li>
                        <li>de instrução &rarr; instruções de linguagem de máquina</li>
                        <li>de diretivas &rarr; não são executáveis. São pseudoinstruções. Não são traduzidas para instruções de LM</li>
                            <ul>
                                <li>são usadas para:</li>
                                    <ul>
                                        <li>definir constantes</li>
                                        <li>designar áreas de memória para armazenar dados</li>
                                        <li>inicializar áreas de memória</li>
                                        <li>inserir dados fixos na memória</li>
                                        <li>permitir referências a outros programas</li>
                                    </ul>
                            </ul>
                    </ul>
                <li>macro ou sub-rotina</li>
                    <ul>
                        <li>seção que pode ser usada diversas vezes</li>
                        <li>pode ser chamada de qualquer ponto do programa</li>
                        <li>sub-rotinas são tratadas pelo hardware em tempo de execução</li>
                        <li>macros são consideradas pelo Assembler em tempo de montagem</li>
                        <li>ex.:</li>
                            <code>
                                macro de uma linha <br>
                                    <code>
                                        %DEFINE B(X) = 2*X <br>
                                        %DEFINE A(X) = 1+B(X) <br> <br>
                            </code>
                                no Assembly aparece a sentença <br>
                                    <code>
                                        MOV AX, A(8) <br> <br>
                                    </code>
                                o Assembler substitui por <br>
                                    <code>
                                        MOV AX, 1+2*B
                                    </code>
                            </code>
                    </ul>
            </ul>
    <h4>Linguagem de máquina</h4>
            <ul>
                <li>instruções executadas diretamente pelo processador</li>
                <li>cada instrução é uma cadeia binária (0 e 1) que contém:</li>
                    <ul>
                        <li>opcode &rarr; código de operação básica. São instruções do processador</li>
                        <li>referências</li>
                        <li>bits de execução</li>
                    </ul>
                <li>as instruções e os endereços de memória devem ser escritos em LM</li>
                <li>cada declaração de Assembly produz uma instrução de LM</li>
                <li>a Assembly é mais simples de programar do que a LM (nomes em vez de binários ou hex)</li>
                <li>o programador de Assembly só precisa lembrar os nomes dos comandos</li>
                <li>o Assembler traduz para a LM</li>
                <li>programador de LM só trabalha com números em HEX ou BIN</li>
            </ul>
    <h4>Linguagem de alto nível ou Assembly?</h4>
            <ul>
                <li>se a aplicação a ser desenvolvida se destina para sistemas diferentes prefira Alto Nível</li>
                <li>nem todas as linguagens de alto nível estão disponíveis para todas as plataformas, então prefira Assembly</li>
                <li>a linguagem de alto nível aumenta a produtividade do programador</li>
                <li>Assembly é utilizada em situações mais específicas (que não possa ser escrita em linguagem de alto nível)</li>
            </ul>
    <hr>
    <h2>Semana 7</h2>
    <p>
        Nesta semana, você conhecerá a linguagem de montagem Assembly (ASM). Ela é fundamental para o funcionamento dos computadores. Se você der uma olhada rápida na linguagem Assembly, perceberá facilmente em que ela se encaixa. Para estudarmos essa linguagem profundamente, temos que entender de arquitetura de computador, pois Assembly é a linguagem que a CPU fala. Nesta semana, pretendemos desenvolver as seguintes habilidades e competências: <br> <br>

    Habilidades e competências:

    <ul>
        <li>Aprender a fazer algoritmos simples em Assembly;</li>
        <li>Entender como fazer programas Assembly dentro do ambiente de linguagem C;</li>
        <li>Conhecer programa Assembly com chamada de sistema e tratamento de interrupção.</li>
    </ul>
    </p>
    <h4>Instruções <mark>MIPS</mark></h4>
        <ul>
            <li>é um exemplo didático em livros Stanford</li>
            <li>tem característica de arquitetura RISC</li>
            <li>segue 4 princípios de projeto:</li>
                <ol type="1">
                    <li>simplicidade &rarr; implementação simples, melhor desempenho e menor custo</li>
                        <ul>
                            <li>as operações tem a mesma forma</li>
                            <li>utiliza 3 operandos: 2 orígens e 1 destino: add a, b, c &rarr; a = b + c</li>
                        </ul>
                    <li>menor é mais rápido</li>
                        <ul>
                            <li>usam registradores como operandos</li>
                            <li>MIPS tem 32 registradores de 32 bits (de 0 a 31)</li>
                            <li>dados de 32 bits são chamados <mark>WORD</mark></li>
                            <li>tipos dos registradores:</li>
                                <ul>
                                    <li><mark>$t0~$t9</mark> &rarr; temporários</li>
                                    <li><mark>$s0~$s7</mark> &rarr; variáveis a serem salvas</li>
                                    <li>registrador 0 ($zero) é a constante 0 e não pode ser sobrescrita</li>
                                </ul>
                            <li>memória &rarr;> é endereçada por byte</li>
                                <ul>
                                    <li>os endereços precisam ser múltiplo de 4</li>
                                    <li>WORDS alinhadas na memória</li>
                                    <li><mark>Big Endian</mark> &rarr; byte mais significativo no endereço menos significativo da palavra</li>
                                    <li>ex.: <code>g = h + A[8] (em C)</code></li>
                                    <code>g em $s1, h em $s2 e endereço de A em $s3 <br>
                                        lw $t0, 32($s3) # load WORD (8 posições multiplicado por 4 em $s3) <br>
                                        add $s1, $s2, $t0
                                    </code>
                                </ul>
                        </ul>
                    <li>faça o caso comum mais rápido</li>
                        <ul>
                            <li>constantes pequenas são comuns</li>
                            <li>operandos imediatos evitam instrução de <mark>LOAD</mark></li>
                            <li>ex:</li>
                                <code>
                                    addi $s3, $s3, 4 (soma 4 em $s3) <br>
                                    addi $s2, $s1, -1 (não existe subração de constante. some valor negativo)
                                </code>
                        </ul>
                </ol>
        </ul>
    <h4>Assembly (<mark>ASM</mark>)</h4>
        <ul>
            <li>é indicado para otimização de operações básicas</li>
            <li>é mais preciso para indicar detalhes de programas (<mark>type-cast</mark>)</li>
            <li>é mais fácil de manipular bugs (aparecem no baixo nível)</li>
            <li>otimiza tempo (velocidade) e espaço</li>
            <li>formato da instrução ASM:</li>
                <code>
                    função (arg1, arg2) <br>
                    opc op1 op2
                </code>
            <li>ex.:</li>
                <code>
                    MOVE destino fonte <br>
                    ADD/SUB op1 op2 <br>
                    JUMP condição localização
                </code>  
            <li>programa em ASM:</li>   
                <ul>
                    <li>etiqueta/rótulo: precedido de dois pontos. Ex.: FORMULA:</li>
                    <li>opcode: MOV-ADD-SUB-JUMP</li>
                    <li>operando: EAX, EBX, ECX, DD(para armazenar dados) (na arquitetura x86)</li>
                    <li>ex. programa: calcular 3 * 10 (10 + 10 + 10)</li>
                        <code>
                            9 ... <br>
                            10 MOVE	RA,	[3]	# [3] é endereço de memória <br>
                            11 MOVE RB,	[4] <br>
                            12 MOVE RC	0	# move valor 0 para RC <br>
                            13 ADD	RC,	RA	# RC = RA (recebe o valor de RA) <br>
                            14 SUB	RB,	1	# subtrai 1 de RB <br>
                            15 JUMP	NZ,	13	# analisa se o resultado é 0 (caso negativo pula para linha 13) <br>
                            16 MOVE	[5],	RC
                        </code>
                </ul>   
            <li>ASM inline</li>      
                <ul>
                    <li>possibilidade de combinar comandos em C com ASM</li>
                    <li>existem 2 sintaxes na arquitetura x86 &rarr; AT&T e Intel</li>
                    <li>o GCC comum usa AT&T</li>
                    <li>para compilar com Intel usa-se: asm=intel</li>
                    <li>estrutura básica:</li>
                        <code>
                            _asm_ ou asm( <br>
                            "instrução\n"		% assembly code <br>
                            "outra instrução"	% assembly code <br>
                            );
                        </code>
                    <li>ex.:</li>
                        <code>
                            int a = 10, b; <br>
                            asm ( <br>
                                "movl %1, %%eax\n" <br>
                                "movl %%eax, %0\n" <br>
                                : "=r" (b) /* output */ <br>
                                : "r" (a) /* input */ <br>
                                : "%eax" /* clobbered register */ <br>
                            );
                        </code>
                </ul>
            <li>Netwide Assembler (<mark>NASM</mark>)</li>
                <ul>
                    <li>montador e desmontador (ASM/Assembler e vice-versa) que suporta IA-32 e x86-64</li>
                    <li>permite desenvolver ASM em diversas arquiteturas (Linux é a mais popular)</li>
                    <li>pode ser escrito em qualquer editor</li>
                    <li>ex.:</li>
                        <code>
                            ex1.asm <br>
                            global _start	# global indica que o identificar ficará acessivel ao linkeditor <br>
                            _start: <br>
                            mov eax, 1 <br>
                            mov ebx, 42 <br>
                            int 0x80 # executa uma IRQ e transfere a execução
                        </code>
                </ul>
        </ul>
    <hr>

</body>
</html>